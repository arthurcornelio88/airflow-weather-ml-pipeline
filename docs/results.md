# Pipeline Weather ML - R√©sultats d'ex√©cution

## üèóÔ∏è Architecture du projet

### Choix de conception : Deux DAGs compl√©mentaires

**Pourquoi deux DAGs s√©par√©s ?**

1. **`weather_data_collection`** (Collection automatique)
   - **Schedule** : `*/2 * * * *` - Collecte toutes les 2 minutes
   - **R√¥le** : Alimenter continuellement la base de donn√©es m√©t√©o
   - **Dur√©e recommand√©e** : 15+ minutes pour accumuler ‚â•15 observations

2. **`weather_training_pipeline`** (Pipeline ML)
   - **Schedule** : `None` - Ex√©cution manuelle sur demande
   - **R√¥le** : Traitement des donn√©es et entra√Ænement ML quand suffisamment de donn√©es
   - **Avantage** : √âvite les ex√©cutions inutiles sans donn√©es suffisantes

### Technologies cl√©s utilis√©es

#### üéØ D√©corateurs Airflow 2.0+
```python
@dag(dag_id='weather_training_pipeline', schedule_interval=None, ...)
def weather_training_pipeline():
    
    @task
    def check_data_availability():
        # Logique de v√©rification
        return {"total_observations": count}
```

**Avantages des d√©corateurs :**
- Code plus propre et pythonique
- XCom implicite automatique
- Gestion native des types Python
- Debugging facilit√©

#### üê≥ Configuration Docker Compose
```yaml
volumes:
  - ./raw_files:/app/raw_files      # Donn√©es brutes
  - ./clean_data:/app/clean_data    # Donn√©es transform√©es
```

**Pourquoi `/app/...` au lieu de `/opt/airflow/...` ?**
- **Isolation** : S√©paration des donn√©es Airflow et des donn√©es m√©tier
- **Partage host-container** : Acc√®s direct aux fichiers depuis l'h√¥te
- **Persistance** : Les donn√©es survivent aux red√©marrages de containers

## üö¶ R√©sultats d'ex√©cution

### V√©rification des donn√©es (Gate condition)

### V√©rification des donn√©es (Gate condition)

```
[2025-09-04, 17:55:31 UTC] {logging_mixin.py:188} INFO - Found 34 weather data files
[2025-09-04, 17:55:31 UTC] {logging_mixin.py:188} INFO - Total observations available: 136
[2025-09-04, 17:55:31 UTC] {logging_mixin.py:188} INFO - ‚úÖ Data check PASSED: 136 observations from 34 files
[2025-09-04, 17:55:31 UTC] {logging_mixin.py:188} INFO - üöÄ Proceeding with data pipeline and ML training...
[2025-09-04, 17:55:31 UTC] {python.py:201} INFO - Done. Returned value was: {'total_files': 34, 'total_observations': 136}
```

**üîß M√©canisme de protection :**
- **Condition d'arr√™t** : `raise ValueError(f"‚ùå Insufficient data:")` si < 15 observations
- **Gate pattern** : Le pipeline ne d√©marre que si les conditions sont remplies
- **Feedback utilisateur** : Messages clairs sur l'√©tat des donn√©es

### Transformation des donn√©es (Tasks 2-3)

**üîÑ Pipeline de transformation :**

```
# Exemple de donn√©es transform√©es (data.csv / fulldata.csv)
      temperature          city  pression                 date
0       293.02           Paris      1013  2025-09-04 17-52-03
1       292.01          London      1009  2025-09-04 17-52-03
2       307.40      Washington      1011  2025-09-04 17-52-03
3       297.41  Belo Horizonte      1020  2025-09-04 17-52-03
4       293.02           Paris      1013  2025-09-04 17-50-03
5       292.01          London      1009  2025-09-04 17-50-03
6       307.40      Washington      1011  2025-09-04 17-50-03
7       298.05  Belo Horizonte      1020  2025-09-04 17-50-03
8       293.31           Paris      1013  2025-09-04 17-48-03
9       292.01          London      1009  2025-09-04 17-48-03

[2025-09-04, 17:55:34 UTC] {logging_mixin.py:188} INFO - Data saved to /app/clean_data/data.csv # si task_2
[2025-09-04, 18:10:02 UTC] {logging_mixin.py:188} INFO - Data saved to /app/clean_data/fulldata.csv # si task_3
```

**üõ†Ô∏è Fonctionnalit√©s de transformation :**
- **Task 2** : 20 fichiers les plus r√©cents ‚Üí `data.csv` (dashboard temps r√©el)
- **Task 3** : Tous les fichiers ‚Üí `fulldata.csv` (entra√Ænement ML)
- **Extraction intelligente** : JSON vers CSV avec colonnes standardis√©es
- **Tri temporel** : Donn√©es organis√©es par date et ville

### Entra√Ænement ML parall√®le (Task 4 - TaskGroup)

**üîß Architecture TaskGroup :**
```python
with TaskGroup("task_4_model_scoring", tooltip="Parallel model training") as model_scoring_group:
    lr_score = task_4_score_linear_regression(prepared_data_paths)
    dt_score = task_4_score_decision_tree(prepared_data_paths)
    rf_score = task_4_score_random_forest(prepared_data_paths)
```

**Avantages du TaskGroup :**
- **Parall√©lisation** : Les 3 mod√®les s'entra√Ænent simultan√©ment
- **Organisation visuelle** : Groupement logique dans l'UI Airflow
- **Performance** : R√©duction du temps total d'ex√©cution
- **Isolation** : Chaque mod√®le dans son propre contexte

#### ü§ñ R√©sultats d'entra√Ænement

**Linear Regression :**
```
[2025-09-04, 18:10:09 UTC] {logging_mixin.py:188} INFO - Computing score with 120 samples using 3-fold CV
[2025-09-04, 18:10:09 UTC] {python.py:201} INFO - Done. Returned value was: -3.5513024605404553
[2025-09-04, 18:10:09 UTC] {taskinstance.py:1138} INFO - Marking task as SUCCESS.
```

**Decision Tree :**
```
[2025-09-04, 18:10:09 UTC] {logging_mixin.py:188} INFO - Computing score with 120 samples using 3-fold CV
[2025-09-04, 18:10:09 UTC] {python.py:201} INFO - Done. Returned value was: -19.811159999999894
[2025-09-04, 18:10:09 UTC] {taskinstance.py:1138} INFO - Marking task as SUCCESS.
```

**Random Forest :**
```
[2025-09-04, 18:10:09 UTC] {logging_mixin.py:188} INFO - Computing score with 120 samples using 3-fold CV
[2025-09-04, 18:10:10 UTC] {python.py:201} INFO - Done. Returned value was: -24.848305572050123
[2025-09-04, 18:10:10 UTC] {taskinstance.py:1138} INFO - Marking task as SUCCESS.
```

#### üìä Tableau comparatif des performances

| Mod√®le | Score (neg_mean_squared_error) | Rang | Temps |
|--------|-------------------------------|------|-------|
| **Linear Regression** | **-3.55** | ü•á 1er | ~1s |
| Decision Tree | -19.81 | ü•à 2√®me | ~1s |
| Random Forest | -24.85 | ü•â 3√®me | ~2s |

**üéØ Analyse :**
- **Vainqueur** : Linear Regression (score le plus proche de 0)
- **M√©trique** : `neg_mean_squared_error` - Plus proche de 0 = meilleur
- **Validation crois√©e adaptative** : 3-fold CV avec 120 √©chantillons
- **Feature engineering** : Variables dummy pour les villes

### XCom - Communication entre t√¢ches

**üîÑ M√©canisme XCom implicite avec les d√©corateurs :**

```python
# Les scores sont automatiquement transmis via XCom
def task_5_choose_best_model(data_paths: dict, lr_score: float, dt_score: float, rf_score: float):
    # lr_score = -3.55 (r√©cup√©r√© automatiquement depuis XCom)
    # dt_score = -19.81 (r√©cup√©r√© automatiquement depuis XCom) 
    # rf_score = -24.85 (r√©cup√©r√© automatiquement depuis XCom)
```

**Avantages de XCom implicite :**
- **Transparence** : Pas de `ti.xcom_pull()` explicite n√©cessaire
- **Type safety** : Les types Python sont pr√©serv√©s (float, dict, etc.)
- **Debugging facilit√©** : Valeurs visibles dans l'UI Airflow XCom
- **Code propre** : Focus sur la logique m√©tier, pas la plomberie Airflow

*[Screenshot Airflow UI XCom √† ins√©rer ici montrant les valeurs transmises]*

### S√©lection finale du mod√®le (Task 5)

```
[2025-09-04, 18:10:13 UTC] {logging_mixin.py:188} INFO - üèÜ Best model: linear_regression with score: -3.5513024605404553
[2025-09-04, 18:10:13 UTC] {logging_mixin.py:188} INFO - Saving model LinearRegression() to /app/clean_data/best_model.joblib
[2025-09-04, 18:10:13 UTC] {logging_mixin.py:188} INFO - ‚úÖ Final model saved to: /app/clean_data/best_model.joblib
[2025-09-04, 18:10:13 UTC] {python.py:201} INFO - Done. Returned value was: /app/clean_data/best_model.joblib
```

**üß† Logique de s√©lection :**
```python
# Comparaison automatique des scores XCom
models = {
    'linear_regression': (LinearRegression(), lr_score),    # -3.55
    'decision_tree': (DecisionTreeRegressor(), dt_score),  # -19.81
    'random_forest': (RandomForestRegressor(), rf_score),  # -24.85
}

# Le meilleur = score le plus proche de 0 (neg_mean_squared_error)
best_model_name = max(models, key=lambda name: models[name][1])
```

**üîß Pipeline final :**
1. **Comparaison** : Analyse des 3 scores via XCom
2. **S√©lection** : Linear Regression identifi√© comme meilleur (-3.55)
3. **R√©entra√Ænement** : Mod√®le retrained sur toutes les donn√©es (120 samples)
4. **Sauvegarde** : Persistance avec `joblib` dans `/app/clean_data/`

*[Screenshot XCom UI + Screenshot VS Code avec model sauvegard√© √† ins√©rer]*

## üéØ Points techniques remarquables

### Gestion de la robustesse
```python
# Adaptation dynamique de la validation crois√©e
def compute_model_score(model, X, y):
    n_samples = len(X)
    cv_folds = min(3, max(2, n_samples))  # Entre 2 et 3 folds selon les donn√©es
```

### Configuration Docker optimis√©e
- **Volumes persistants** : `/app/` pour donn√©es m√©tier vs `/opt/airflow/` pour Airflow
- **S√©paration des responsabilit√©s** : raw_files (input) / clean_data (output)
- **Acc√®s host** : Possibilit√© d'inspecter les fichiers directement

## üìà Bilan du projet

**‚úÖ Objectifs atteints :**
- Pipeline ML complet de A √† Z
- Collecte automatique de donn√©es m√©t√©o
- Entra√Ænement de mod√®les en parall√®le
- S√©lection automatique du meilleur mod√®le
- Sauvegarde et persistance du mod√®le final

**üöÄ Technologies ma√Ætris√©es :**
- Airflow 2.0+ avec d√©corateurs
- TaskGroup pour parall√©lisation
- XCom implicite pour communication
- Docker Compose avec volumes
- Scikit-learn pour ML
- API REST (OpenWeatherMap)
- Feature engineering automatique

**üìä R√©sultats quantitatifs :**
- 136 observations m√©t√©o collect√©es
- 3 mod√®les entra√Æn√©s simultan√©ment  
- 120 √©chantillons pour l'entra√Ænement final
- Linear Regression s√©lectionn√© (score: -3.55)
- Pipeline ex√©cut√© en ~5 minutes


